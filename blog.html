<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Blog | Neural Signal Projects</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" />
  <link rel="stylesheet" href="css/style.css" />
</head>
<body>

<!-- Header -->
<div id="header-placeholder"></div>

<main class="container mt-5">

  <!-- Blog Post 1 -->
  <div class="blog-card mb-4">
    <div class="blog-title">Decoding Neural Signals from EEG for Motor Imagery</div>
    <div class="blog-date">Posted on April 30, 2025</div>
    <div class="blog-snippet">
      <div class="full-text collapsed">
        This project involved decoding motor imagery EEG signals from the PhysioNet dataset using a deep learning pipeline.
        I designed and evaluated CNN and LSTM models to classify imagined hand and foot movements. Preprocessing included
        bandpass filtering, ICA-based artifact removal, and feature normalization. The goal was to improve classification
        accuracy for brain-computer interface applications. It is very challenging to develop effective brain computer interfaces (BCIs) to decode human intentions from brain activity. While we can see many studies that have focused on language-related neural signals, the brain also processes information through non-linguistic stimuli, such as motor actions and visual inputs. This study primarily  investigates decoding motor intention, more specific to imagined or executed limb movement using electroencephalography (EEG) data from the PhysioNet Motor Movement/Imagery Dataset (EEGMMIDB). First of all,  EEG signals were preprocessed with band-pass filtering, segmented into epochs, and classified using machine learning models. Our method uses two different models, Convolutional Neural Networks (CNNs) to capture local spatial features and Transformer-based architectures to model long-range temporal dependencies. In addition, we extract spatial-spectral-temporal features to enhance classification performance. Using two different models, CNNs and Transformer, Accuracy, left/right hand precision and f1-scores were calculated to evaluate the performance. We are able to achieve around 61% accuracy in both architectures. These findings could be contributing to the growing field of neural decoding and support the development of assistive technologies and neurorehabilitation tools.
      </div>
      <a href="#" class="read-more-link text-primary">Read more</a>
    </div>
  </div>

  <!-- Blog Post 2 -->
  <div class="blog-card mb-4">
    <div class="blog-title">Biomedical Named Entity Recognition using Reinforcement Learning</div>
    <div class="blog-date">Posted on April 30, 2025</div>
    <div class="blog-snippet">
      <div class="full-text collapsed">
        In this research, I applied policy gradient methods to optimize a Bio-NER model trained on PubTator data.
        Traditional supervised models struggle with rare and domain-specific biomedical terms. By modeling NER
        as a sequential decision-making problem, my RL-based approach improved precision and recall. The system
        was benchmarked against BERT and BiLSTM-CRF baselines.
        This project proposes an approach to Biomedical Named Entity Recognition (NER) by utilizing Reinforcement Learning (RL). Conventional NER systems depend on supervised learning, which can struggle with ambiguous concepts. Through repetitive interactions with the text, the proposed system will learn to enhance entity recognition by integrating RL, which will allow it to handle diverse biomedical entities more efficiently. Along with the MedMentions dataset, a sizable corpus annotated with UMLS (Unified Medical Language System), PubMedBERT, a state-of-the-art language model, will be used in this system.
The steps involved in this system design include data preprocessing, baseline model development, RL integration, and finally evaluation. In the first step, the MedMentions dataset will be tokenized using PubMedBERT’s tokenizer. Then, using supervised learning, PubMedBERT will be finetuned for NER. This baseline model will act as a benchmark for evaluating the performance improvements introduced by reinforcement learning. 
The proposed system will consist of three main components: the Environment, the Agent, and the Reward Function. A series of tokens will denote the Environment, and the agent’s job will be to predict the entity tags for each token, for example, D for Disease, M for Medicine, and so forth. The policy used by the agent will be PubMedBERT, which will be initialized with weights from the optimized baseline models. Based on the correctness of the agent’s prediction, feedback in the form of the reward function will be provided to the agent. Learning to increase cumulative rewards, the agent will be able to improve its entity recognition accuracy, and the system will be able to adjust to rare entities.
With the incorporation of RL, the system will be able to generalize better, adapting to a range of biomedical literature. The proposed system is expected to accomplish the task with higher entity recognition accuracy compared to traditional supervised models, particularly for complex biomedical terms. PubMedBERT is a language model pre-trained from scratch on PubMed abstracts, achieving state-of-the-art performance on a wide range of biomedical NLP tasks, and demonstrating the importance of domain-specific pre-training for biomedical text understanding [4]. The utilization of PubMedBERT assures that the system gains from this domain-specific pre-training, while the RL framework presents a novel optimization technique for NER. This system has potential applications in drug discovery, biomedical research, literature analysis, and clinical decision support, where precise entity recognition can help diagnose illnesses and suggest treatments.

      </div>
      <a href="#" class="read-more-link text-primary">Read more</a>
    </div>
  </div>

</main>

<!-- Footer -->
<div id="footer-placeholder"></div>

<!-- Load Header and Footer -->
<script>
  fetch("header.html")
    .then(res => res.text())
    .then(data => {
      document.getElementById("header-placeholder").innerHTML = data;
    });

  fetch("footer.html")
    .then(res => res.text())
    .then(data => {
      document.getElementById("footer-placeholder").innerHTML = data;
    });
</script>

<!-- Read More Script -->
<script>
  document.addEventListener('DOMContentLoaded', () => {
    document.querySelectorAll('.read-more-link').forEach(link => {
      link.addEventListener('click', function (e) {
        e.preventDefault();
        const fullText = this.previousElementSibling;
        fullText.classList.toggle('collapsed');
        this.textContent = fullText.classList.contains('collapsed') ? 'Read more' : 'Read less';
      });
    });
  });
</script>

<!-- Bootstrap JS -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>

</body>
</html>
